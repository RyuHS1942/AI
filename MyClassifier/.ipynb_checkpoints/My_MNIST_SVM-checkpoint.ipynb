{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte'\n",
    "                                % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('./data', kind='train')\n",
    "X_test, y_test = load_mnist('./data', kind='test')\n",
    "\n",
    "X_train=np.concatenate((X_train, X_test))\n",
    "y_train=np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(60000, 784)\n",
    "\n",
    "    return images\n",
    "\n",
    "X_testall = load_mnist('./data', kind='testall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sample_number:\t:70000, column_number:784\n",
      "testall_sample_number\t:60000, column_number:784\n"
     ]
    }
   ],
   "source": [
    "print('train_sample_number:\\t:%d, column_number:%d' %(X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "print('testall_sample_number\\t:%d, column_number:%d' %(X_testall.shape[0], X_testall.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassifier(object):    \n",
    "    \"\"\"\n",
    "    ovr\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1000, eta=0.01, batch_size=60, epochs=200, epsilon=1e-8, \n",
    "                 shuffle=True, params=None, w=0, b=0):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "#         self.params['aver_w'] = w\n",
    "#         self.params['aver_b'] = b\n",
    "        \n",
    "    def fit(self, X, y, params=None, w=0, b=0, testscore = None, eval_score=None):\n",
    "        # X_num = m, X_fea = n\n",
    "        # m = np.shape(X)[0], n = np.shape(X)[1]\n",
    "        \n",
    "        X_num, X_fea = np.shape(X)\n",
    "        #X_num=60000 X_fea=28*28\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #class_num=10\n",
    "        \n",
    "        if params is None:\n",
    "            print('fit params=None')\n",
    "            self.params = {\n",
    "                'w': np.random.randn(X_fea, self.class_num), #(10, 784) 정규분포난수\n",
    "                'b': np.random.randn(1, self.class_num),\n",
    "                'w_': np.random.randn(X_fea, self.class_num),\n",
    "                'b_': np.random.randn(1, self.class_num),\n",
    "                'tmpw': 0,\n",
    "                'tmpb': 0\n",
    "            }\n",
    "        cnt=1\n",
    "        if eval_score is None:\n",
    "            self.score_val = 0\n",
    "                \n",
    "        for Xi in range(self.epochs):\n",
    "            s_data, s_labels = self.shuffling(X, y)\n",
    "            encoded_y=self.encoding(s_labels)\n",
    "            avg_loss = 0\n",
    "            batch_count = int(X_num / self.batch_size)\n",
    "            for t in range(int(batch_count)):\n",
    "#               self.params['tmpw'] = temp_w, self.params['tmpb'] = temp_b\n",
    "                batch_X, batch_y, bs=self.batching(s_data, encoded_y, t)\n",
    "                batch_X = np.reshape(batch_X, (bs, X_fea))\n",
    "                batch_y = np.reshape(batch_y, (bs, self.class_num))\n",
    "                z = self.net_input(batch_X)\n",
    "                loss = self.hinge_loss(batch_y, z)\n",
    "                self.update_w_b(batch_X, batch_y, z, bs, cnt)\n",
    "                cnt+=1\n",
    "                avg_loss += loss\n",
    "                self.update_count += 1\n",
    "##ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
    "# aver_w = w_ , w_ = w\n",
    "            self.params['tmpw'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['w_'] + (1/(cnt+1))*self.params['w'])\n",
    "            self.params['tmpb'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['b_'] + (1/(cnt+1))*self.params['b'])\n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            print(\"epochs: \", Xi)\n",
    "            print(\"prev_score: \", prev_score)\n",
    "            print(\"pres_score: \", pres_score,\"\\n\")\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "            if self.det_weight(X, y, 1) < self.det_weight(X, y): # temp_w, temp_b\n",
    "                self.params['w_'] = self.params['tmpw']\n",
    "                self.params['b_'] = self.params['tmpb']\n",
    "            avg_loss /= batch_count\n",
    "        return self\n",
    "    \n",
    "    def det_weight(self, X, y, aver=0):\n",
    "        if aver:\n",
    "            w1 = self.params['w_']\n",
    "            b1 = self.params['b_']\n",
    "        else:\n",
    "            w1 = self.params['tmpw']\n",
    "            b1 = self.params['tmpb']\n",
    "        temp = np.dot(X, w1) + b1\n",
    "#         temp = temp.T\n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        sco = np.mean(pred == y)\n",
    "        return sco\n",
    "    \n",
    "    def update_w_b(self, batch_X, batch_y, z, bs, cnt):\n",
    "        n = np.shape(batch_X)[1]  # num of features\n",
    "        delta_w = np.zeros(self.params['w'].shape)\n",
    "        delta_b = np.zeros(self.params['b'].shape)\n",
    "        z = np.reshape(z, (bs, self.class_num))\n",
    "        temp = 1 - np.multiply(batch_y, z)\n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        y_temp = np.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        delta_w = -(1 / bs) * np.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        delta_b = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "        self.params['w'] = self.params['w'] - (self.eta / (1 + self.epsilon * cnt)) * delta_w\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * delta_b\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def hinge_loss(self, y, z):\n",
    "        loss = 1 - np.multiply(y, z)\n",
    "        loss[loss < 0] = 0\n",
    "        loss = np.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):  # net_input() = forward_prop(), generate z\n",
    "        z = np.matmul(X, self.params['w']) + self.params['b']\n",
    "        return z\n",
    "\n",
    "    def encoding(self, y):\n",
    "        encoded_y=-1*np.ones((np.shape(y)[0],self.class_num))\n",
    "        for i in range(np.shape(y)[0]):\n",
    "            encoded_y[i,y[i]] = 1\n",
    "        return encoded_y\n",
    "                \n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "    \n",
    "    def batching(self, X, y, t):                         \n",
    "        batch_X = X[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        batch_y = y[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        last_size = min(len(X), (t+1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        return batch_X, batch_y,last_size\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = np.shape(X)[0]\n",
    "        class_score = self.net_input(X)  # return z\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs,\n",
    "               'eta': self.eta, 'w':self.params['w_'], 'b':self.params['b_']}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def test(self, X, w, b):\n",
    "        z = np.matmul(X, np.array(w)) + np.array(b)\n",
    "        p = np.argmax(len(w), axis=1)\n",
    "        for i in range(len(X)):\n",
    "            self.img(i,X,p)\n",
    "            \n",
    "    def img(self, row, X, p):\n",
    "        image = np.zeros((28,28))\n",
    "        for i in range(0,28):\n",
    "            for j in range(0,28):\n",
    "                pix = 28*i+j\n",
    "                image[i,j] = X[row, pix]\n",
    "        plt.imshow(image, cmap = 'gray')\n",
    "        plt.title('%d)pridicted_value: %d' %(row+1, p))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit params=None\n",
      "epochs:  0\n",
      "prev_score:  0\n",
      "pres_score:  0.3997857142857143 \n",
      "\n",
      "epochs:  1\n",
      "prev_score:  0.3997857142857143\n",
      "pres_score:  0.5637714285714286 \n",
      "\n",
      "epochs:  2\n",
      "prev_score:  0.5637714285714286\n",
      "pres_score:  0.6289571428571429 \n",
      "\n",
      "epochs:  3\n",
      "prev_score:  0.6289571428571429\n",
      "pres_score:  0.6660714285714285 \n",
      "\n",
      "epochs:  4\n",
      "prev_score:  0.6660714285714285\n",
      "pres_score:  0.6911571428571428 \n",
      "\n",
      "epochs:  5\n",
      "prev_score:  0.6911571428571428\n",
      "pres_score:  0.7072142857142857 \n",
      "\n",
      "epochs:  6\n",
      "prev_score:  0.7072142857142857\n",
      "pres_score:  0.7215428571428572 \n",
      "\n",
      "epochs:  7\n",
      "prev_score:  0.7215428571428572\n",
      "pres_score:  0.7324857142857143 \n",
      "\n",
      "epochs:  8\n",
      "prev_score:  0.7324857142857143\n",
      "pres_score:  0.7419428571428571 \n",
      "\n",
      "epochs:  9\n",
      "prev_score:  0.7419428571428571\n",
      "pres_score:  0.7487142857142857 \n",
      "\n",
      "epochs:  10\n",
      "prev_score:  0.7487142857142857\n",
      "pres_score:  0.7551285714285715 \n",
      "\n",
      "epochs:  11\n",
      "prev_score:  0.7551285714285715\n",
      "pres_score:  0.7612857142857142 \n",
      "\n",
      "epochs:  12\n",
      "prev_score:  0.7612857142857142\n",
      "pres_score:  0.7664714285714286 \n",
      "\n",
      "epochs:  13\n",
      "prev_score:  0.7664714285714286\n",
      "pres_score:  0.7703857142857143 \n",
      "\n",
      "epochs:  14\n",
      "prev_score:  0.7703857142857143\n",
      "pres_score:  0.7749714285714285 \n",
      "\n",
      "epochs:  15\n",
      "prev_score:  0.7749714285714285\n",
      "pres_score:  0.7794428571428571 \n",
      "\n",
      "epochs:  16\n",
      "prev_score:  0.7794428571428571\n",
      "pres_score:  0.7821 \n",
      "\n",
      "epochs:  17\n",
      "prev_score:  0.7821\n",
      "pres_score:  0.7860571428571429 \n",
      "\n",
      "epochs:  18\n",
      "prev_score:  0.7860571428571429\n",
      "pres_score:  0.7887857142857143 \n",
      "\n",
      "epochs:  19\n",
      "prev_score:  0.7887857142857143\n",
      "pres_score:  0.7912 \n",
      "\n",
      "epochs:  20\n",
      "prev_score:  0.7912\n",
      "pres_score:  0.7941 \n",
      "\n",
      "epochs:  21\n",
      "prev_score:  0.7941\n",
      "pres_score:  0.7968428571428572 \n",
      "\n",
      "epochs:  22\n",
      "prev_score:  0.7968428571428572\n",
      "pres_score:  0.799 \n",
      "\n",
      "epochs:  23\n",
      "prev_score:  0.799\n",
      "pres_score:  0.8016285714285715 \n",
      "\n",
      "epochs:  24\n",
      "prev_score:  0.8016285714285715\n",
      "pres_score:  0.804 \n",
      "\n",
      "epochs:  25\n",
      "prev_score:  0.804\n",
      "pres_score:  0.8057142857142857 \n",
      "\n",
      "epochs:  26\n",
      "prev_score:  0.8057142857142857\n",
      "pres_score:  0.8082142857142857 \n",
      "\n",
      "epochs:  27\n",
      "prev_score:  0.8082142857142857\n",
      "pres_score:  0.8102714285714285 \n",
      "\n",
      "epochs:  28\n",
      "prev_score:  0.8102714285714285\n",
      "pres_score:  0.8117 \n",
      "\n",
      "epochs:  29\n",
      "prev_score:  0.8117\n",
      "pres_score:  0.8138142857142857 \n",
      "\n",
      "epochs:  30\n",
      "prev_score:  0.8138142857142857\n",
      "pres_score:  0.8146857142857142 \n",
      "\n",
      "epochs:  31\n",
      "prev_score:  0.8146857142857142\n",
      "pres_score:  0.8161571428571428 \n",
      "\n",
      "epochs:  32\n",
      "prev_score:  0.8161571428571428\n",
      "pres_score:  0.8176857142857142 \n",
      "\n",
      "epochs:  33\n",
      "prev_score:  0.8176857142857142\n",
      "pres_score:  0.8187714285714286 \n",
      "\n",
      "epochs:  34\n",
      "prev_score:  0.8187714285714286\n",
      "pres_score:  0.8204 \n",
      "\n",
      "epochs:  35\n",
      "prev_score:  0.8204\n",
      "pres_score:  0.8211 \n",
      "\n",
      "epochs:  36\n",
      "prev_score:  0.8211\n",
      "pres_score:  0.8231714285714286 \n",
      "\n",
      "epochs:  37\n",
      "prev_score:  0.8231714285714286\n",
      "pres_score:  0.8242142857142857 \n",
      "\n",
      "epochs:  38\n",
      "prev_score:  0.8242142857142857\n",
      "pres_score:  0.8251714285714286 \n",
      "\n",
      "epochs:  39\n",
      "prev_score:  0.8251714285714286\n",
      "pres_score:  0.8268428571428571 \n",
      "\n",
      "epochs:  40\n",
      "prev_score:  0.8268428571428571\n",
      "pres_score:  0.8274 \n",
      "\n",
      "epochs:  41\n",
      "prev_score:  0.8274\n",
      "pres_score:  0.8278714285714286 \n",
      "\n",
      "epochs:  42\n",
      "prev_score:  0.8278714285714286\n",
      "pres_score:  0.8296 \n",
      "\n",
      "epochs:  43\n",
      "prev_score:  0.8296\n",
      "pres_score:  0.8302 \n",
      "\n",
      "epochs:  44\n",
      "prev_score:  0.8302\n",
      "pres_score:  0.8312714285714286 \n",
      "\n",
      "epochs:  45\n",
      "prev_score:  0.8312714285714286\n",
      "pres_score:  0.832 \n",
      "\n",
      "epochs:  46\n",
      "prev_score:  0.832\n",
      "pres_score:  0.8327285714285714 \n",
      "\n",
      "epochs:  47\n",
      "prev_score:  0.8327285714285714\n",
      "pres_score:  0.8331 \n",
      "\n",
      "epochs:  48\n",
      "prev_score:  0.8331\n",
      "pres_score:  0.834 \n",
      "\n",
      "epochs:  49\n",
      "prev_score:  0.834\n",
      "pres_score:  0.8356142857142858 \n",
      "\n",
      "epochs:  50\n",
      "prev_score:  0.8356142857142858\n",
      "pres_score:  0.8356428571428571 \n",
      "\n",
      "epochs:  51\n",
      "prev_score:  0.8356428571428571\n",
      "pres_score:  0.8362428571428572 \n",
      "\n",
      "epochs:  52\n",
      "prev_score:  0.8362428571428572\n",
      "pres_score:  0.8375285714285714 \n",
      "\n",
      "epochs:  53\n",
      "prev_score:  0.8375285714285714\n",
      "pres_score:  0.8382428571428572 \n",
      "\n",
      "epochs:  54\n",
      "prev_score:  0.8382428571428572\n",
      "pres_score:  0.8385571428571429 \n",
      "\n",
      "epochs:  55\n",
      "prev_score:  0.8385571428571429\n",
      "pres_score:  0.8399428571428571 \n",
      "\n",
      "epochs:  56\n",
      "prev_score:  0.8399428571428571\n",
      "pres_score:  0.8409285714285715 \n",
      "\n",
      "epochs:  57\n",
      "prev_score:  0.8409285714285715\n",
      "pres_score:  0.8412 \n",
      "\n",
      "epochs:  58\n",
      "prev_score:  0.8412\n",
      "pres_score:  0.8415428571428571 \n",
      "\n",
      "epochs:  59\n",
      "prev_score:  0.8415428571428571\n",
      "pres_score:  0.8429857142857143 \n",
      "\n",
      "epochs:  60\n",
      "prev_score:  0.8429857142857143\n",
      "pres_score:  0.8431285714285714 \n",
      "\n",
      "epochs:  61\n",
      "prev_score:  0.8431285714285714\n",
      "pres_score:  0.8441428571428572 \n",
      "\n",
      "epochs:  62\n",
      "prev_score:  0.8441428571428572\n",
      "pres_score:  0.8445285714285714 \n",
      "\n",
      "epochs:  63\n",
      "prev_score:  0.8445285714285714\n",
      "pres_score:  0.8448428571428571 \n",
      "\n",
      "epochs:  64\n",
      "prev_score:  0.8448428571428571\n",
      "pres_score:  0.8454857142857143 \n",
      "\n",
      "epochs:  65\n",
      "prev_score:  0.8454857142857143\n",
      "pres_score:  0.8458714285714286 \n",
      "\n",
      "epochs:  66\n",
      "prev_score:  0.8458714285714286\n",
      "pres_score:  0.8467571428571429 \n",
      "\n",
      "epochs:  67\n",
      "prev_score:  0.8467571428571429\n",
      "pres_score:  0.8469428571428571 \n",
      "\n",
      "epochs:  68\n",
      "prev_score:  0.8469428571428571\n",
      "pres_score:  0.8474857142857143 \n",
      "\n",
      "epochs:  69\n",
      "prev_score:  0.8474857142857143\n",
      "pres_score:  0.8479 \n",
      "\n",
      "epochs:  70\n",
      "prev_score:  0.8479\n",
      "pres_score:  0.8481 \n",
      "\n",
      "epochs:  71\n",
      "prev_score:  0.8481\n",
      "pres_score:  0.8483857142857143 \n",
      "\n",
      "epochs:  72\n",
      "prev_score:  0.8483857142857143\n",
      "pres_score:  0.8495714285714285 \n",
      "\n",
      "epochs:  73\n",
      "prev_score:  0.8495714285714285\n",
      "pres_score:  0.8503714285714286 \n",
      "\n",
      "epochs:  74\n",
      "prev_score:  0.8503714285714286\n",
      "pres_score:  0.8507 \n",
      "\n",
      "epochs:  75\n",
      "prev_score:  0.8507\n",
      "pres_score:  0.8499714285714286 \n",
      "\n",
      "epochs:  76\n",
      "prev_score:  0.8507\n",
      "pres_score:  0.8504571428571429 \n",
      "\n",
      "epochs:  77\n",
      "prev_score:  0.8507\n",
      "pres_score:  0.8512714285714286 \n",
      "\n",
      "epochs:  78\n",
      "prev_score:  0.8512714285714286\n",
      "pres_score:  0.8509571428571429 \n",
      "\n",
      "epochs:  79\n",
      "prev_score:  0.8512714285714286\n",
      "pres_score:  0.8521 \n",
      "\n",
      "epochs:  80\n",
      "prev_score:  0.8521\n",
      "pres_score:  0.8515285714285714 \n",
      "\n",
      "epochs:  81\n",
      "prev_score:  0.8521\n",
      "pres_score:  0.8533571428571428 \n",
      "\n",
      "epochs:  82\n",
      "prev_score:  0.8533571428571428\n",
      "pres_score:  0.8532142857142857 \n",
      "\n",
      "epochs:  83\n",
      "prev_score:  0.8533571428571428\n",
      "pres_score:  0.8536142857142857 \n",
      "\n",
      "epochs:  84\n",
      "prev_score:  0.8536142857142857\n",
      "pres_score:  0.8539 \n",
      "\n",
      "epochs:  85\n",
      "prev_score:  0.8539\n",
      "pres_score:  0.8537857142857143 \n",
      "\n",
      "epochs:  86\n",
      "prev_score:  0.8539\n",
      "pres_score:  0.8543428571428572 \n",
      "\n",
      "epochs:  87\n",
      "prev_score:  0.8543428571428572\n",
      "pres_score:  0.8541142857142857 \n",
      "\n",
      "epochs:  88\n",
      "prev_score:  0.8543428571428572\n",
      "pres_score:  0.8550142857142857 \n",
      "\n",
      "epochs:  89\n",
      "prev_score:  0.8550142857142857\n",
      "pres_score:  0.8552 \n",
      "\n",
      "epochs:  90\n",
      "prev_score:  0.8552\n",
      "pres_score:  0.8551571428571428 \n",
      "\n",
      "epochs:  91\n",
      "prev_score:  0.8552\n",
      "pres_score:  0.8557428571428571 \n",
      "\n",
      "epochs:  92\n",
      "prev_score:  0.8557428571428571\n",
      "pres_score:  0.8563285714285714 \n",
      "\n",
      "epochs:  93\n",
      "prev_score:  0.8563285714285714\n",
      "pres_score:  0.8567285714285714 \n",
      "\n",
      "epochs:  94\n",
      "prev_score:  0.8567285714285714\n",
      "pres_score:  0.8559 \n",
      "\n",
      "epochs:  95\n",
      "prev_score:  0.8567285714285714\n",
      "pres_score:  0.8568714285714286 \n",
      "\n",
      "epochs:  96\n",
      "prev_score:  0.8568714285714286\n",
      "pres_score:  0.8568714285714286 \n",
      "\n",
      "epochs:  97\n",
      "prev_score:  0.8568714285714286\n",
      "pres_score:  0.8571285714285715 \n",
      "\n",
      "epochs:  98\n",
      "prev_score:  0.8571285714285715\n",
      "pres_score:  0.8564714285714286 \n",
      "\n",
      "epochs:  99\n",
      "prev_score:  0.8571285714285715\n",
      "pres_score:  0.8566285714285714 \n",
      "\n",
      "epochs:  100\n",
      "prev_score:  0.8571285714285715\n",
      "pres_score:  0.8570857142857143 \n",
      "\n",
      "epochs:  101\n",
      "prev_score:  0.8571285714285715\n",
      "pres_score:  0.8578714285714286 \n",
      "\n",
      "epochs:  102\n",
      "prev_score:  0.8578714285714286\n",
      "pres_score:  0.8567571428571429 \n",
      "\n",
      "epochs:  103\n",
      "prev_score:  0.8578714285714286\n",
      "pres_score:  0.8583714285714286 \n",
      "\n",
      "epochs:  104\n",
      "prev_score:  0.8583714285714286\n",
      "pres_score:  0.8585 \n",
      "\n",
      "epochs:  105\n",
      "prev_score:  0.8585\n",
      "pres_score:  0.8571428571428571 \n",
      "\n",
      "epochs:  106\n",
      "prev_score:  0.8585\n",
      "pres_score:  0.8583857142857143 \n",
      "\n",
      "epochs:  107\n",
      "prev_score:  0.8585\n",
      "pres_score:  0.8576 \n",
      "\n",
      "epochs:  108\n",
      "prev_score:  0.8585\n",
      "pres_score:  0.8589285714285714 \n",
      "\n",
      "epochs:  109\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8585285714285714 \n",
      "\n",
      "epochs:  110\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8588857142857143 \n",
      "\n",
      "epochs:  111\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8584714285714286 \n",
      "\n",
      "epochs:  112\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8586 \n",
      "\n",
      "epochs:  113\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8586428571428572 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  114\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8586142857142857 \n",
      "\n",
      "epochs:  115\n",
      "prev_score:  0.8589285714285714\n",
      "pres_score:  0.8599428571428571 \n",
      "\n",
      "epochs:  116\n",
      "prev_score:  0.8599428571428571\n",
      "pres_score:  0.8595285714285714 \n",
      "\n",
      "epochs:  117\n",
      "prev_score:  0.8599428571428571\n",
      "pres_score:  0.8601571428571428 \n",
      "\n",
      "epochs:  118\n",
      "prev_score:  0.8601571428571428\n",
      "pres_score:  0.8593857142857143 \n",
      "\n",
      "epochs:  119\n",
      "prev_score:  0.8601571428571428\n",
      "pres_score:  0.8594285714285714 \n",
      "\n",
      "epochs:  120\n",
      "prev_score:  0.8601571428571428\n",
      "pres_score:  0.8601142857142857 \n",
      "\n",
      "epochs:  121\n",
      "prev_score:  0.8601571428571428\n",
      "pres_score:  0.8602285714285715 \n",
      "\n",
      "epochs:  122\n",
      "prev_score:  0.8602285714285715\n",
      "pres_score:  0.8593 \n",
      "\n",
      "epochs:  123\n",
      "prev_score:  0.8602285714285715\n",
      "pres_score:  0.8604142857142857 \n",
      "\n",
      "epochs:  124\n",
      "prev_score:  0.8604142857142857\n",
      "pres_score:  0.8600571428571429 \n",
      "\n",
      "epochs:  125\n",
      "prev_score:  0.8604142857142857\n",
      "pres_score:  0.8602571428571428 \n",
      "\n",
      "epochs:  126\n",
      "prev_score:  0.8604142857142857\n",
      "pres_score:  0.8602 \n",
      "\n",
      "epochs:  127\n",
      "prev_score:  0.8604142857142857\n",
      "pres_score:  0.8606857142857143 \n",
      "\n",
      "epochs:  128\n",
      "prev_score:  0.8606857142857143\n",
      "pres_score:  0.8607571428571429 \n",
      "\n",
      "epochs:  129\n",
      "prev_score:  0.8607571428571429\n",
      "pres_score:  0.8611 \n",
      "\n",
      "epochs:  130\n",
      "prev_score:  0.8611\n",
      "pres_score:  0.8609 \n",
      "\n",
      "epochs:  131\n",
      "prev_score:  0.8611\n",
      "pres_score:  0.8608428571428571 \n",
      "\n",
      "epochs:  132\n",
      "prev_score:  0.8611\n",
      "pres_score:  0.861 \n",
      "\n",
      "epochs:  133\n",
      "prev_score:  0.8611\n",
      "pres_score:  0.8614571428571428 \n",
      "\n",
      "epochs:  134\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8602714285714286 \n",
      "\n",
      "epochs:  135\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8611428571428571 \n",
      "\n",
      "epochs:  136\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8614 \n",
      "\n",
      "epochs:  137\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8602285714285715 \n",
      "\n",
      "epochs:  138\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8596285714285714 \n",
      "\n",
      "epochs:  139\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8613285714285714 \n",
      "\n",
      "epochs:  140\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8607428571428571 \n",
      "\n",
      "epochs:  141\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8613285714285714 \n",
      "\n",
      "epochs:  142\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8613857142857143 \n",
      "\n",
      "epochs:  143\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8612428571428571 \n",
      "\n",
      "epochs:  144\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8609285714285714 \n",
      "\n",
      "epochs:  145\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8610857142857142 \n",
      "\n",
      "epochs:  146\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8611285714285715 \n",
      "\n",
      "epochs:  147\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8611714285714286 \n",
      "\n",
      "epochs:  148\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8605142857142857 \n",
      "\n",
      "epochs:  149\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8603857142857143 \n",
      "\n",
      "epochs:  150\n",
      "prev_score:  0.8614571428571428\n",
      "pres_score:  0.8619 \n",
      "\n",
      "epochs:  151\n",
      "prev_score:  0.8619\n",
      "pres_score:  0.8609714285714286 \n",
      "\n",
      "epochs:  152\n",
      "prev_score:  0.8619\n",
      "pres_score:  0.8620428571428571 \n",
      "\n",
      "epochs:  153\n",
      "prev_score:  0.8620428571428571\n",
      "pres_score:  0.8617857142857143 \n",
      "\n",
      "epochs:  154\n",
      "prev_score:  0.8620428571428571\n",
      "pres_score:  0.8624285714285714 \n",
      "\n",
      "epochs:  155\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8611285714285715 \n",
      "\n",
      "epochs:  156\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8612285714285715 \n",
      "\n",
      "epochs:  157\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8604571428571428 \n",
      "\n",
      "epochs:  158\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8619428571428571 \n",
      "\n",
      "epochs:  159\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8608857142857143 \n",
      "\n",
      "epochs:  160\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8613428571428572 \n",
      "\n",
      "epochs:  161\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8618857142857143 \n",
      "\n",
      "epochs:  162\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8613857142857143 \n",
      "\n",
      "epochs:  163\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8619857142857142 \n",
      "\n",
      "epochs:  164\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8615571428571429 \n",
      "\n",
      "epochs:  165\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8605714285714285 \n",
      "\n",
      "epochs:  166\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8608857142857143 \n",
      "\n",
      "epochs:  167\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8622 \n",
      "\n",
      "epochs:  168\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8607 \n",
      "\n",
      "epochs:  169\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8608571428571429 \n",
      "\n",
      "epochs:  170\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8615428571428572 \n",
      "\n",
      "epochs:  171\n",
      "prev_score:  0.8624285714285714\n",
      "pres_score:  0.8625285714285714 \n",
      "\n",
      "epochs:  172\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8609142857142857 \n",
      "\n",
      "epochs:  173\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8604857142857143 \n",
      "\n",
      "epochs:  174\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8622142857142857 \n",
      "\n",
      "epochs:  175\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8620285714285715 \n",
      "\n",
      "epochs:  176\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8615857142857143 \n",
      "\n",
      "epochs:  177\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8618 \n",
      "\n",
      "epochs:  178\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8611857142857143 \n",
      "\n",
      "epochs:  179\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8618571428571429 \n",
      "\n",
      "epochs:  180\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8615571428571429 \n",
      "\n",
      "epochs:  181\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8610285714285715 \n",
      "\n",
      "epochs:  182\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8620857142857142 \n",
      "\n",
      "epochs:  183\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8610428571428571 \n",
      "\n",
      "epochs:  184\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8624285714285714 \n",
      "\n",
      "epochs:  185\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8621 \n",
      "\n",
      "epochs:  186\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8616857142857143 \n",
      "\n",
      "epochs:  187\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8620428571428571 \n",
      "\n",
      "epochs:  188\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8618857142857143 \n",
      "\n",
      "epochs:  189\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8615142857142857 \n",
      "\n",
      "epochs:  190\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8618571428571429 \n",
      "\n",
      "epochs:  191\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8621571428571428 \n",
      "\n",
      "epochs:  192\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8611142857142857 \n",
      "\n",
      "epochs:  193\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8615857142857143 \n",
      "\n",
      "epochs:  194\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8615857142857143 \n",
      "\n",
      "epochs:  195\n",
      "prev_score:  0.8625285714285714\n",
      "pres_score:  0.8625428571428572 \n",
      "\n",
      "epochs:  196\n",
      "prev_score:  0.8625428571428572\n",
      "pres_score:  0.862 \n",
      "\n",
      "epochs:  197\n",
      "prev_score:  0.8625428571428572\n",
      "pres_score:  0.8617428571428571 \n",
      "\n",
      "epochs:  198\n",
      "prev_score:  0.8625428571428572\n",
      "pres_score:  0.8615428571428572 \n",
      "\n",
      "epochs:  199\n",
      "prev_score:  0.8625428571428572\n",
      "pres_score:  0.8628857142857143 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.myClassifier at 0x7f11dd46c950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine=myClassifier()\n",
    "mine.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000,\n",
       " 'batch_size': 60,\n",
       " 'epochs': 200,\n",
       " 'eta': 0.01,\n",
       " 'w': array([[-0.43461041,  1.86608293, -0.32560851, ..., -1.23268637,\n",
       "         -0.72931137, -0.26319607],\n",
       "        [-1.07997731,  1.23478768,  1.70846202, ..., -1.00440248,\n",
       "         -1.71379625, -0.32022391],\n",
       "        [ 1.1666789 , -0.47431144, -0.93370042, ..., -0.63684866,\n",
       "          1.38703138,  0.29233714],\n",
       "        ...,\n",
       "        [ 0.54185094,  1.89871007,  0.77674838, ...,  0.39194368,\n",
       "         -0.37954935, -2.45311229],\n",
       "        [ 1.34381139,  0.83887221, -0.19775881, ...,  1.54064329,\n",
       "          0.92287899, -0.15780622],\n",
       "        [ 0.63777873, -0.77430483,  1.00425742, ..., -0.218096  ,\n",
       "          1.87791917,  0.89552121]]),\n",
       " 'b': array([[-0.40601242,  0.98214184,  1.51740877,  0.17460516,  0.63970432,\n",
       "          1.26477389,  1.11073433,  0.72155997,  1.18320796,  0.74224253]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_= mine.get_params()\n",
    "\n",
    "list_['w']\n",
    "w__=pd.DataFrame(list_['w'])\n",
    "w__.to_csv(\"final_w.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_['b']\n",
    "b__=pd.DataFrame(list_['b'])\n",
    "b__.to_csv(\"final_b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2w=pd.read_csv('/home/ryu/AI/MyClassifier/final_w.csv')\n",
    "list_2b=pd.read_csv('/home/ryu/AI/MyClassifier/final_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Need to specify at least one of 'labels', 'index' or 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d8bb0384fc08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_2w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4117\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4118\u001b[0m         )\n\u001b[1;32m   4119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3905\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3906\u001b[0m             raise ValueError(\n\u001b[0;32m-> 3907\u001b[0;31m                 \u001b[0;34m\"Need to specify at least one of 'labels', \"\u001b[0m \u001b[0;34m\"'index' or 'columns'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3908\u001b[0m             )\n\u001b[1;32m   3909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Need to specify at least one of 'labels', 'index' or 'columns'"
     ]
    }
   ],
   "source": [
    "list_2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.406012</td>\n",
       "      <td>0.982142</td>\n",
       "      <td>1.517409</td>\n",
       "      <td>0.174605</td>\n",
       "      <td>0.639704</td>\n",
       "      <td>1.264774</td>\n",
       "      <td>1.110734</td>\n",
       "      <td>0.72156</td>\n",
       "      <td>1.183208</td>\n",
       "      <td>0.742243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -0.406012  0.982142  1.517409  0.174605  0.639704  1.264774   \n",
       "\n",
       "          6        7         8         9  \n",
       "0  1.110734  0.72156  1.183208  0.742243  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (10000, 11), indices imply (784, 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (10000, 11), indices imply (784, 11)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f0108b0c7591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_2w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_2b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5351daa74714>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, X, w, b)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_wrap__\u001b[0;34m(self, result, context)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_axes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     \u001b[0;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (10000, 11), indices imply (784, 11)"
     ]
    }
   ],
   "source": [
    "mine.test(X_testall,list_2w,list_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
