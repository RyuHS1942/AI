{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e594ea30b07b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMySVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0;36m1\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mSVM\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class MySVM(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    1 vs 1 SVM (binary classification)\n",
    "    \"\"\"\n",
    "    def __init__(self, C=0.1, eta=0.001, batch_size=1, max_iter=25, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        constructor of MyBinarySVM class.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.eta = eta\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.num_classes = 0\n",
    "#         self.beta1 = 0.9\n",
    "#         self.beta2 = 0.99\n",
    "    \n",
    "    def fit(self, X, y=None, params=None):\n",
    "        \"\"\"\n",
    "        fit method for training svm\n",
    "        \n",
    "        Arguments:\n",
    "        --------------------------\n",
    "        X: image data. (60000, 784)\n",
    "        y: label data. (60000, 1)\n",
    "        \n",
    "        Returns:\n",
    "        --------------------------\n",
    "        Z: class score\n",
    "        \"\"\"\n",
    "\n",
    "        m = np.shape(X)[0] #행 개수 60000\n",
    "        n = np.shape(X)[1] #열 개수 784\n",
    "        self.num_classes = len(np.unique(y)) #클래스 수 = 10\n",
    "        \n",
    "        y_encoded = self.encode_y(y)\n",
    "        \n",
    "        # create weights.\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'W': np.random.randn(n, self.num_classes), #(784,10) 정규분포난수\n",
    "                'b': np.random.randn(1, self.num_classes)\n",
    "            }\n",
    "\n",
    "        cnt = 1\n",
    "        \n",
    "        for epoch in range(self.max_iter):\n",
    "            \n",
    "            X_shuffled, y_shuffled = self.shuffle(X, y_encoded)\n",
    "\n",
    "            avg_loss = 0\n",
    "            \n",
    "            batch_count = int(np.ceil(np.shape(X)[0] / self.batch_size))\n",
    "            \n",
    "            for t in range(batch_count):\n",
    "                m = np.shape(X_shuffled)[0] #60000\n",
    "        \n",
    "        X_batch = X_shuffled[t * self.batch_size : min(m, (t + 1) * self.batch_size)]\n",
    "        y_batch = y_shuffled[t * self.batch_size : min(m, (t + 1) * self.batch_size)]\n",
    "        bs = min(m, (t + 1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        \n",
    "                X_batch, y_batch, bs = self.next_batch(X_shuffled, y_shuffled, t)\n",
    "                \n",
    "                X_batch = np.reshape(X_batch, (bs, n))\n",
    "                y_batch = np.reshape(y_batch, (bs, self.num_classes))\n",
    "                Z = self.forward_prop(X_batch)\n",
    "                Z = np.reshape(Z, (bs, self.num_classes))\n",
    "                loss = self.compute_cost(y_batch, Z)\n",
    "                self.backward_prop(X_batch, y_batch, Z, bs, cnt)\n",
    "            \n",
    "                # accumulate loss\n",
    "                avg_loss += loss\n",
    "                cnt += 1\n",
    "        \n",
    "            # logging\n",
    "            avg_loss /= batch_count\n",
    "            if epoch % (self.max_iter / 10) == 0:\n",
    "                print('Cost at epoch {0}: {1}'.format(epoch, avg_loss))\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def encode_y(self, y):\n",
    "        y_encoded = np.ones((np.shape(y)[0], self.num_classes)) #1로 이루어진 배열(60000,10)\n",
    "        \n",
    "        for i in range(self.num_classes):\n",
    "            y_encoded[:, i][y != i] = -1\n",
    "            \n",
    "        return y_encoded\n",
    "    \n",
    "    def backward_prop(self, X, y, Z, bs, cnt):\n",
    "        \"\"\"\n",
    "        update weights\n",
    "        \n",
    "        Arguments:\n",
    "        ----------------------------\n",
    "        X: images e.g (BATCH_SIZE, 784)\n",
    "        y: labels e.g (BATCH_SIZE, 1)\n",
    "        Z: class score after forward propagation\n",
    "        params: weights dictionary(map in other programming language)\n",
    "        eta: learning rate\n",
    "        \n",
    "        Returns:\n",
    "        ----------------------------\n",
    "        params: weights dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        # number of features\n",
    "        n = np.shape(X)[1]\n",
    "        \n",
    "        # differential vector of loss function to update weights\n",
    "        dw = np.zeros(self.params['W'].shape)\n",
    "        db = np.zeros(self.params['b'].shape)\n",
    "        \n",
    "        Z = np.reshape(Z, (bs, self.num_classes))\n",
    "        temp = np.multiply(y, Z)\n",
    "        temp = 1 - temp\n",
    "        \n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        \n",
    "        y_temp = np.multiply(y, temp.reshape(bs, self.num_classes))\n",
    "        \n",
    "        dw = -(1 / bs) * np.matmul(X.T, y_temp) + (1 / self.C) * self.params['W']\n",
    "        db = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "\n",
    "#         if cnt == 1:\n",
    "#             self.M['W'] = dw\n",
    "#             self.M['b'] = db\n",
    "#         else:\n",
    "#             self.M['W'] = (self.beta1 * self.M['W'] + (1 - self.beta1) * dw)\n",
    "#             self.M['b'] = (self.beta1 * self.M['b'] + (1 - self.beta1) * db)\n",
    "        \n",
    "#         if cnt == 1:\n",
    "#             self.V['W'] = dw ** 2\n",
    "#             self.V['b'] = db ** 2\n",
    "#         else:\n",
    "#             self.V['W'] = (self.beta2 * self.V['W'] + (1 - self.beta2) * (dw ** 2))\n",
    "#             self.V['b'] = (self.beta2 * self.V['b'] + (1 - self.beta2) * (db ** 2))\n",
    "    \n",
    "#         self.M['W'] = (self.beta1 * self.M['W'] + (1 - self.beta1) * dw) / (1 - self.beta1 ** cnt)\n",
    "#         self.M['b'] = (self.beta1 * self.M['b'] + (1 - self.beta1) * db) / (1 - self.beta1 ** cnt)\n",
    "        \n",
    "#         self.V['W'] = (self.beta2 * self.V['W'] + (1 - self.beta2) * np.square(dw)) / (1 - self.beta2 ** cnt)\n",
    "#         self.V['b'] = (self.beta2 * self.V['b'] + (1 - self.beta2) * np.square(db)) / (1 - self.beta2 ** cnt)\n",
    "\n",
    "        # update weights\n",
    "#         self.params['W'] = self.params['W'] - np.divide(self.eta * self.M['W'], np.sqrt(self.V['W']) + self.epsilon)\n",
    "#         self.params['b'] = self.params['b'] - np.divide(self.eta * self.M['b'], np.sqrt(self.V['b']) + self.epsilon)\n",
    "        \n",
    "        self.params['W'] = self.params['W'] - (self.eta / (1 + self.epsilon * cnt)) * dw\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * db\n",
    "\n",
    "#         self.params['W'] = self.params['W'] - (self.eta / (1 + self.epsilon * cnt)) * dw\n",
    "#         self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * db\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        m = np.shape(X)[0]\n",
    "        \n",
    "        class_score = self.forward_prop(X)\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
