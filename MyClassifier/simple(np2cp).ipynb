{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "p5Io-lfl9LiH",
    "outputId": "edb3b56d-3345-4783-d0df-f524fba5bd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  1580  100  1580    0     0   5129      0 --:--:-- --:--:-- --:--:--  5113\n",
      "+ apt -y -q install cuda-libraries-dev-10-0\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-430\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
      "+ pip install -q cupy-cuda100  chainer \n",
      "\u001b[K     |████████████████████████████████| 382.9MB 33kB/s \n",
      "\u001b[?25h+ set +ex\n",
      "Installation succeeded!\n"
     ]
    }
   ],
   "source": [
    "!curl https://colab.chainer.org/install | sh -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcjEfo_D8TKT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import struct\n",
    "import os\n",
    "import cupy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.ndimage import interpolation\n",
    "import random\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "## loading mnist dataset\n",
    "import random\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte'\n",
    "                                % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-patterns-idx3-ubyte'\n",
    "                               % kind)\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = numpy.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                               imgpath.read(16))\n",
    "        images = numpy.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "#### Loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('./', kind='train')\n",
    "X_test, y_test = load_mnist('./', kind='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    return interpolation.affine_transform(image,affine,offset=offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskewAll(X):\n",
    "    currents = []\n",
    "    for i in range(len(X)):\n",
    "        currents.append(deskew(X[i].reshape(28,28)).flatten())\n",
    "    return np.array(currents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deskewed = deskewAll(X_train)\n",
    "X_test_deskewed = deskewAll(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eq5MGBXw8orF"
   },
   "outputs": [],
   "source": [
    "X_train=X_train_deskewed/255\n",
    "X_test=X_test_deskewed/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hog-72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "def calc_hog_features(X, image_shape=(28, 28), pixels_per_cell=(8, 8)):\n",
    "    fd_list = []\n",
    "    for row in X:\n",
    "        img = row.reshape(image_shape)\n",
    "        fd = hog(img, orientations=8, pixels_per_cell=pixels_per_cell, cells_per_block=(1, 1))\n",
    "        fd_list.append(fd)\n",
    "    \n",
    "    return np.array(fd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoged_X_train = calc_hog_features(X_train, pixels_per_cell=(8, 8))\n",
    "hoged_X_test = calc_hog_features(X_test, pixels_per_cell=(8, 8))\n",
    "hoged_X_fea=hoged_X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution-26*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenel = [\n",
    "    [1,0,-1],\n",
    "    [1,0,-1],\n",
    "    [1,0,-1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(X,kenel):\n",
    "    con_X =np.zeros((26,26))\n",
    "    for y in range(1,26):\n",
    "        for x in range(1,26):\n",
    "            temp = [\n",
    "                [X[y*28+x-29],X[y*28+x-28],X[y*28+x-27]],\n",
    "                [X[y*28+x-1],X[y*28+x],X[y*28+x+1]],\n",
    "                [X[y*28+x+27],X[y*28+x+28],X[y*28+x+29]]\n",
    "            ]\n",
    "            mul_=np.array(temp)*cp.array(kenel)\n",
    "            sum_=np.sum(mul_)\n",
    "            con_X[y-1][x-1]=sum_\n",
    "    return con_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_X_train=convolution(X_train,kenel)\n",
    "con_x_test=convolution(X_test,kenel)\n",
    "con_X_fea=con_X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zmli9_hc8FkQ",
    "outputId": "7a852be8-1e1f-4448-8460-fdad5a1c7bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input\\n    argv : PATH\\n    eg) python team1.py ./data/newtrain-images-idx3-ubyte ./data/newtrain-labels-idx1-ubyte ./data/mnist_new_testall-patterns-idx3-ubyte\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myClassifier(object):\n",
    "    \"\"\"\n",
    "    ovr\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1000, eta=0.1, batch_size=20, epochs=100, epsilon=1e-8, \n",
    "                 shuffle=True, params=None, w=0, b=0):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.class_num = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.update_count = 0\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def fit(self, X, y, params=None, w=0, b=0, testscore = None, eval_score=None):\n",
    "        # X_num = m, X_fea = n\n",
    "        # m = np.shape(X)[0], n = np.shape(X)[1]\n",
    "        \n",
    "        #np# X_num, X_fea = np.shape(X)\n",
    "        X_num = X.shape[0]\n",
    "        X_fea = X.shape[1]\n",
    "        #X_num=60000 X_fea=28*28\n",
    "        self.class_num=len(np.unique(y))\n",
    "        #class_num=10\n",
    "        \n",
    "        if params is None:\n",
    "            print('fit params=None')\n",
    "            self.params = {\n",
    "                'w': np.random.randn(X_fea + con_X_fea + hoged_X_fea, self.class_num), #(10, 784) 정규분포난수\n",
    "                'b': np.random.randn(1, self.class_num),\n",
    "                'w_': np.random.randn(X_fea + con_X_fea + hoged_X_fea, self.class_num),\n",
    "                'b_': np.random.randn(1, self.class_num),\n",
    "                'tmpw': 0,\n",
    "                'tmpb': 0\n",
    "            }\n",
    "        cnt=1\n",
    "        if eval_score is None:\n",
    "            self.score_val = 0\n",
    "            \n",
    "        for Xi in range(self.epochs):\n",
    "            s_data, s_labels = self.shuffling(X, y) # tuple object\n",
    "            encoded_y=self.encoding(s_labels)\n",
    "            avg_loss = 0\n",
    "            batch_count = int(X_num / self.batch_size)\n",
    "            for t in range(int(batch_count)):\n",
    "#                self.params['tmpw'] = temp_w, self.params['tmpb'] = temp_b\n",
    "                batch_X, batch_y, bs = self.batching(s_data, encoded_y, t) # tuple:batch_X\n",
    "                ###\n",
    "                numpy.reshape(batch_X, (bs, X_fea + con_X_fea + hoged_X_fea))\n",
    "                numpy.reshape(batch_y, (bs, self.class_num))\n",
    "                ###\n",
    "                print(type(batch_X))\n",
    "                batch_X = np.array(batch_X)\n",
    "                batch_y = np.array(batch_y)\n",
    "                # batch_X = np.reshape(batch_X, (bs, X_fea))\n",
    "                # batch_y = np.reshape(batch_y, (bs, self.class_num))\n",
    "                z = self.net_input(batch_X)\n",
    "                self.update_w_b(batch_X, batch_y, z, bs, cnt)\n",
    "                cnt+=1\n",
    "                self.update_count += 1\n",
    "\n",
    "            self.params['tmpw'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['w_'] + (1/(cnt+1))*self.params['w'])\n",
    "            self.params['tmpb'] = (cnt * (cnt/(cnt+1)) * \n",
    "                                   self.params['b_'] + (1/(cnt+1))*self.params['b'])\n",
    "            prev_score = self.score_val\n",
    "            pres_score = self.score(X, y)\n",
    "            if Xi % 10 == 0:\n",
    "                print(\"epochs: \", Xi)\n",
    "                print(\"prev_score: \", prev_score)\n",
    "                print(\"pres_score: \", pres_score)\n",
    "                print()\n",
    "            if prev_score < pres_score:\n",
    "                self.score_val = pres_score\n",
    "            if self.det_weight(X, y, 1) < self.det_weight(X, y): # temp_w, temp_b\n",
    "                self.params['w_'] = self.params['tmpw']\n",
    "                self.params['b_'] = self.params['tmpb']\n",
    "        return self\n",
    "    \n",
    "    def det_weight(self, X, y, aver=0):\n",
    "        if aver:\n",
    "            w1 = self.params['w_']\n",
    "            b1 = self.params['b_']\n",
    "        else:\n",
    "            w1 = self.params['tmpw']\n",
    "            b1 = self.params['tmpb']\n",
    "        temp = np.dot(X, w1) + b1\n",
    "#         temp = temp.T\n",
    "        pred = np.argmax(temp, axis=1)\n",
    "        sco = np.mean(pred == y)\n",
    "        return sco\n",
    "    \n",
    "    def update_w_b(self, batch_X, batch_y, z, bs, cnt):\n",
    "        n = batch_X.shape[1]  # num of features\n",
    "        delta_w = np.zeros(self.params['w'].shape)\n",
    "        delta_b = np.zeros(self.params['b'].shape)\n",
    "        z = np.reshape(z, (bs, self.class_num))\n",
    "        temp = 1 - np.multiply(batch_y, z)\n",
    "        temp[temp <= 0] = 0\n",
    "        temp[temp > 0] = 1\n",
    "        y_temp = np.multiply(batch_y, temp.reshape(bs, self.class_num))\n",
    "        delta_w = -(1 / bs) * np.matmul(batch_X.T, y_temp) + (1 / self.C) * self.params['w']\n",
    "        delta_b = -(1 / bs) * np.sum(y_temp, axis=0)\n",
    "        self.params['w'] = self.params['w'] - (self.eta / (1 + self.epsilon * cnt)) * delta_w\n",
    "        self.params['b'] = self.params['b'] - (self.eta / (1 + self.epsilon * cnt)) * delta_b\n",
    "        \n",
    "        return self.params\n",
    "    \n",
    "    def hinge_loss(self, y, z):\n",
    "        loss = 1 - np.multiply(y, z)\n",
    "        loss[loss < 0] = 0\n",
    "        loss = np.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "    def net_input(self, X):  # net_input() = forward_prop(), generate z\n",
    "        z = np.matmul(X, self.params['w']) + self.params['b']\n",
    "        return z\n",
    "\n",
    "    def encoding(self, y):\n",
    "        y_array=np.array(y).reshape(-1,1)\n",
    "\n",
    "        enc=OneHotEncoder()\n",
    "        enc.fit(y_array)\n",
    "        y_enc=enc.transform(y_array).toarray()\n",
    "        \n",
    "        encoded_y=-1*np.ones((np.shape(y_test)[0],10))\n",
    "        \n",
    "        y_enc=y_enc * 2 + encoded_y\n",
    "        return y_enc\n",
    "\n",
    "    def shuffling(self, X, y):\n",
    "        temp_s=list(zip(X,y))\n",
    "        random.shuffle(temp_s)\n",
    "        X,y=zip(*temp_s)\n",
    "        return X,y\n",
    "\n",
    "    def batching(self, X, y, t):             \n",
    "        batch_X = X[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        batch_y = y[t * self.batch_size : min(len(X), (t+1) * self.batch_size)]\n",
    "        last_size = min(len(X), (t+1) * self.batch_size) - t * self.batch_size\n",
    "        \n",
    "        return batch_X, batch_y, last_size\n",
    "    \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        class_score = self.net_input(X)  # return z\n",
    "        pred = np.argmax(class_score, axis=1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        score = np.mean(pred == y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'C':self.C, 'batch_size':self.batch_size, 'epochs':self.epochs,\n",
    "               'eta': self.eta, 'w':self.params['w'], 'b':self.params['b']}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def test(self, X, w, b):\n",
    "        print(\"============== TESTING =================\")\n",
    "        z = np.dot(X, np.array(w)) + np.array(b)\n",
    "        p = np.argmax(z, axis=1)\n",
    "        return p\n",
    "\n",
    "def main(training_image, training_label, test_image):\n",
    "    ## loading mnist dataset ##\n",
    "    raw_train = read_idx(training_image)\n",
    "    train_data = np.reshape(raw_train, (X_train.shape[0], X_train.shape[1]))\n",
    "    train_label = read_idx(training_label)\n",
    "\n",
    "    raw_test = read_idx(test_image)\n",
    "    test_data = np.reshape(raw_test, (X_test.shape[0], X_test.shape[1]))\n",
    "    ## test_label = read_idx(\"./data/test-labels-idx1-ubyte\")\n",
    "\n",
    "    ## Standardzation ##\n",
    "    # X_train_std = StandardScaler().fit_transform(train_data)\n",
    "    # X_test_std = StandardScaler().fit_transform(test_data)\n",
    "    X_train_std = train_data / 255\n",
    "    X_test_std = test_data / 255\n",
    "\n",
    "    ## SVM model ##\n",
    "    mysvm = myClassifier(C=1000, batch_size=20, epochs=200, eta= 0.01).fit(X_train_std, train_label)\n",
    "\n",
    "    w = mysvm.get_params()['w']\n",
    "    b = mysvm.get_params()['b']\n",
    "\n",
    "    pred = mysvm.test(X_test_std, w, b)\n",
    "\n",
    "    file=open('./prediction.txt','w')\n",
    "    for i in range(len(pred)):\n",
    "        file.write('%s\\n' %pred[i])\n",
    "    file.close()\n",
    "\n",
    "\"\"\" input\n",
    "    argv : PATH\n",
    "    eg) python team1.py ./data/newtrain-images-idx3-ubyte ./data/newtrain-labels-idx1-ubyte ./data/mnist_new_testall-patterns-idx3-ubyte\n",
    "\"\"\"\n",
    "# if __name__ == \"__main__\":\n",
    "#     main(sys.argv[1], sys.argv[2], sys.argv[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9NN857-85mG"
   },
   "outputs": [],
   "source": [
    "x = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "# X_train_gpu = np.asarray(x)\n",
    "# y_train_gpu = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "colab_type": "code",
    "id": "SC8vmev4AOk0",
    "outputId": "6c21202e-7760-4e8b-de6a-dec8cd8a3d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit params=None\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-8d5ae4187831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-396ee1da2b05>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, params, w, b, testscore, eval_score)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m# batch_X = np.reshape(batch_X, (bs, X_fea))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cupy/creation/from_data.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(obj, dtype, copy, order, subok, ndmin)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported dtype object"
     ]
    }
   ],
   "source": [
    "mine=myClassifier()\n",
    "mine.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoXeF3SotQ_5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simple(np2cp).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
